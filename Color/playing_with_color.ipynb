{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with Color\n",
    "stough 202-\n",
    "\n",
    "In this activity we'll use what we've learned about color to try and **enhance** or even **compress** them without too much perceptual loss. The other notebooks in this folder should be useful here, particularly [color_intro](./color_intro.ipynb), [color_HSV](./color_HSV.ipynb), and [color_YCbCr](./color_YCbCr.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "You can borrow the imports from any of the other notebooks in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "import skimage.color as color\n",
    "from ipywidgets import VBox, HBox, FloatSlider\n",
    "from copy import deepcopy\n",
    "\n",
    "# For importing from alternative directory sources\n",
    "import sys  \n",
    "sys.path.insert(0, '../dip_utils')\n",
    "\n",
    "import matrix_utils\n",
    "from vis_utils import (vis_rgb_cube,\n",
    "                       vis_hsv_cube,\n",
    "                       vis_hists,\n",
    "                       lab_uniform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Enhancement: Improving the Color of an Image\n",
    "Take a look at  `../dip_pics/sf.jpg` and try the `vis_hists` function on it to the distributions of the R,G,B channels. Of course you can try this out with any image you like of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = plt.imread('../dip_pics/sf.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd808237187a4fdc8356e3aa11242162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_hists(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To me it looks like the clouds shrouding the [Golden Gate Bridge](https://en.wikipedia.org/wiki/Golden_Gate_Bridge) are too dark, not blue enough really for my tastes. You can see this in the relative color distributions as well, with the blue component maxing out below the midpoint of the intensity range. \n",
    "\n",
    "Try adding some blue to the image to really make those clouds pop better. **Be careful** to use the `arr_info` to understand both the `dtype` and understood range of your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((947, 1421, 3), dtype('uint8'), 0, 255)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_utils.arr_info(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2734a3cdc9be4e849337e04b15d0c977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bChannel = deepcopy(I)\n",
    "bChannel[:,:,0]=0\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2)\n",
    "ax[0].imshow(I)\n",
    "ax[0].set_title(\"Original\")\n",
    "\n",
    "ax[1].imshow(bChannel)\n",
    "ax[1].set_title(\"Blue Channel\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ehancement: Improving Contrast through Saturation of Color\n",
    "Take a look at `../dip_pics/world_overexposed.jpg`. Here we have a very overexposed image. (Again, find any overexposed image you like). What this means generally is that we have a lot of what should be color/Hue showing up as mostly white; as in, it's been mixed with too much white. See the [color_HSV](./color_HSV.ipynb) demo titled \"Viewing the planes of the HSV space\" and see what happens as saturation $S_{HSV}$ approaches zero. \n",
    "\n",
    "Try converting the image to HSV and then scaling the saturation component to improve the color purity of all those washed-out pixels. Then convert back to RGB and see if it's improved. **Remember**, from the [skimage documentation](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.rgb2hsv), that the hsv channels are all in $[0,1]$, so when you do the scaling you might need to `np.clip`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "import skimage.color as color\n",
    "from ipywidgets import VBox, HBox, FloatSlider\n",
    "from copy import deepcopy\n",
    "\n",
    "# For importing from alternative directory sources\n",
    "import sys  \n",
    "sys.path.insert(0, '../dip_utils')\n",
    "\n",
    "from matrix_utils import arr_info\n",
    "from vis_utils import (vis_rgb_cube,\n",
    "                       vis_hsv_cube,\n",
    "                       vis_hists,\n",
    "                       lab_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b4f5c91047434cab65b432cf7381e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((960, 1280, 3), dtype('uint8'), 31, 255)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = plt.imread('../dip_pics/world_overexposed.jpg')\n",
    "vis_hists(I)\n",
    "arr_info(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d900546fe0f54c47a52f76dcb7abc515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "In = I - I.min()\n",
    "In = In/In.max()\n",
    "In = (255*In).astype(np.uint8)\n",
    "vis_hists(In)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ac445268a74b3d84d8791fd68c1c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f88c82554a8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1,2, figsize=(8,3), sharex=True, sharey=True)\n",
    "ax[0].imshow(I)\n",
    "ax[1].imshow(In)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSV = color.rgb2hsv(I)\n",
    "\n",
    "H, S, V = np.split(HSV, indices_or_sections=3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1d7b4e49064eabbaa3b5ddedb095cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f88c1b55390>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_info(S)\n",
    "plt.figure()\n",
    "plt.imshow(S, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S = newvalue*np.ones_like(V)\n",
    "S2 = S.copy()/S.max()\n",
    "S2[S2 > .2] = S2[S2 > .2] +.2\n",
    "S2 = S2.clip(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((960, 1280, 1), dtype('float64'), 0.0, 1.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_info(S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSV = np.dstack((H,S2,V))\n",
    "I_change = color.hsv2rgb(HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e055c0c269f4be1979dc818777f098d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f88c1ac3710>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1,2, figsize=(8,3), sharex=True, sharey=True)\n",
    "ax[0].imshow(I)\n",
    "ax[1].imshow(I_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB = plt.imread('../dip_pics/world_overexposed.jpg')\n",
    "HSV = color.rgb2hsv(RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeSat(newSat):\n",
    "    global HSV\n",
    "    change = newSat - HSV[...,0].mean()\n",
    "    \n",
    "    IC = HSV.copy()\n",
    "    IC[...,0] = np.fmod(IC[...,0]+change, 1)\n",
    "    \n",
    "    return np.clip(IC, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/remote/anaconda-3.7-deeplearn/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: tight_layout not applied: number of columns in subplot specifications must be multiples of one another.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7713ec87b1c44089f07080af6e1f8f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FloatSlider(value=0.3332523035072134, description='Saturation', max=1.0, step=0.01), Canvas(too…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ioff()\n",
    "# plt.clf()\n",
    "\n",
    "sat_mean = HSV[...,0].mean()\n",
    "\n",
    "# A slider to set the saturation.\n",
    "sat_slider = FloatSlider(\n",
    "    orientation='horizontal',\n",
    "    value=sat_mean,\n",
    "    min=0.00,\n",
    "    max=1.00,\n",
    "    step=0.01,\n",
    "    description='Saturation'\n",
    ")\n",
    "\n",
    "# Setting up the figure.\n",
    "fig_args = {'num':' ', 'frameon':True, 'sharex':True, 'sharey':True}\n",
    "fig, ax = plt.subplots(1,2, figsize=(8,3), **fig_args)\n",
    "\n",
    "ih = changeSat(sat_mean)\n",
    "irgb = color.hsv2rgb(ih)\n",
    "\n",
    "odisp = ax[0].imshow(RGB)\n",
    "rdisp = ax[1].imshow(irgb)\n",
    "\n",
    "ax[0].set_title(f'Original ({sat_mean:.03f})')\n",
    "rtext = ax[1].set_title(f'Saturation: {sat_mean:.03f}')\n",
    "\n",
    "def update_image(change):\n",
    "    global odisp, rdisp, HSV, rtext, ih\n",
    "    \n",
    "    I_rgb = color.hsv2rgb(changeSat(change.new))\n",
    "    rdisp.set_array(I_rgb)\n",
    "    rtext.set_text(f'Saturation: {change.new:.03f}')\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "sat_slider.observe(update_image, names='value')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "VBox([sat_slider, fig.canvas])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-eb0116c8719e>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-eb0116c8719e>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    In a prior activity we reduced the bit-depth of the RGB color channels of an image and saw how that *quantization* affected the image quality, creating sharp edges of color change in what would be smoothly graded areas. So one of the limits of potentially compressing images relates to the minimum bit-depth that can maintain perceptual fidelity.\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## 3. Compression: Reducing the Bit-Depth of an Image to Save Space\n",
    "In a prior activity we reduced the bit-depth of the RGB color channels of an image and saw how that *quantization* affected the image quality, creating sharp edges of color change in what would be smoothly graded areas. So one of the limits of potentially compressing images relates to the minimum bit-depth that can maintain perceptual fidelity.\n",
    "\n",
    "But in this module's materials, we've seen that some color spaces (HSV, YCbCr, and L*a*b*) include some dimension that captures the brightness/luminance/intensity representation of an image separately from the \"color\" aspect. [YCbCr](./color_YCbCr.ipynb) in particular is used a lot in compression for precisely this reason.\n",
    "\n",
    "In the below cells, try considering an image like `../dip_pics/bellagio.jpg` or `../dip_pics/mountainSpring.jpg` for example. \n",
    "\n",
    "- See what happens with you reduce the bit-depth to 4-4-4 in RGB. \n",
    "- Then try reducing the bit-depth to 6-3-3 but **in the YCbCr** space. Here we're saving the same number of bits per pixel, but differentially quantizing (and therefore compressing) the **Luminance** and color components.\n",
    "\n",
    "It may be useful here to define a function that quantizes a 2D `ndarray` instead of a whole image at once. Luckily, it's likely the same quantization function you've already written may suffice. I include a useable version here just to help.  \n",
    "\n",
    "**Be careful**: [`skimage.color.ycbcr2rgb`](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.ycbcr2rgb) expects 'float64' data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5aeb41057f6410e8d554449b0326cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "import skimage.color as color\n",
    "from ipywidgets import VBox, HBox, FloatSlider\n",
    "from copy import deepcopy\n",
    "\n",
    "# For importing from alternative directory sources\n",
    "import sys  \n",
    "sys.path.insert(0, '../dip_utils')\n",
    "\n",
    "from matrix_utils import arr_info\n",
    "from vis_utils import (vis_rgb_cube,\n",
    "                       vis_hsv_cube,\n",
    "                       vis_hists,\n",
    "                       lab_uniform)\n",
    "\n",
    "def quantize_bitdepth(C, bitdepth=8):\n",
    "    \"\"\"\n",
    "    quantize_bitdepth(C, bitdepth=8): return a copy of the array C where the elements are\n",
    "    limited to 2**bitdepth unique values. Tries to handle a float image just in case.\n",
    "    \"\"\"\n",
    "    assert bitdepth <= 8, f'quantize_bitdepth error: expects bitdepth <= 8, got {bitdepth}'\n",
    "    \n",
    "    shft_amt = 8 - bitdepth\n",
    "    \n",
    "    J = np.uint8(C)\n",
    "    if C.dtype == 'float':\n",
    "        J = np.uint8(256 * (J/J.max()))\n",
    "        \n",
    "    return np.uint8((J >> shft_amt)*(255/(2**bitdepth-1)))\n",
    "\n",
    "\n",
    "B = plt.imread('../dip_pics/bellagio.jpg')\n",
    "YCb = color.rgb2ycbcr(B)\n",
    "\n",
    "fig_args = {'num':' ', 'frameon':True, 'sharex':True, 'sharey':True}\n",
    "fig, ax = plt.subplots(1,3, figsize=(8,3), **fig_args)\n",
    "\n",
    "QB = quantize_bitdepth(B, 1)\n",
    "Qycb = quantize_bitdepth(YCb, 4)\n",
    "\n",
    "orig = ax[0].imshow(B)\n",
    "rgbnew = ax[1].imshow(QB)\n",
    "ycbnew = ax[2].imshow(color.ycbcr2rgb(Qycb.astype('float64')))\n",
    "\n",
    "#ycb = ax[2].imshow(Qybc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
